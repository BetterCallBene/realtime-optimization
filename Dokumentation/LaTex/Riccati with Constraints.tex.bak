\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[german]{babel}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}

\setcounter{MaxMatrixCols}{20}


\begin{document}

  \begin{large}
  \textbf{Vorbereitung}
  \end{large} \\
  Diskretisierung des Optimierungsproblems. Für jeden Zeitschritt $k$ erhalten wir ein Problem $ P^k (x_k) $
  \begin{align*}
  \min_{\begin{array}{c} s_{k},...,s_{N}\\ q_{k},...,q_{N} \end{array}} \sum_{i=k}^{N-1} f_{i}(s_{i},q_{i}) \ \  
  s.t. \ \left\lbrace \begin{array}{c}
  x_{k} - s_{k} = 0 \\
  h_i (s_i ,q_i ) - s_{i+1} = 0 \ \ \forall i = k, ... , N-1 \end{array} \right. 
  \end{align*}
  Mit 
  \begin{align*}
  h_i (s_i ,q_i ) = s_{i} + \Delta t g_{i}(s_{i},q_{i})
  \end{align*}
  In diesem Fall steht $ g $ für die diskretisierte ODE
  \begin{align*}
  \dot{x}_{i} = g_{i} (s_{i},q_{i})
  \end{align*}
  Die zu den Problemen $ P^{k}(x_{k}) $ gehörenden Lagrangegleichungen lauten wie folgt:
  \begin{align*}
  L^{k}(y) = \sum_{i=k}^{N-1} f_{i}(s_{i},q_{i})
  + \lambda_{k}^{T}(x_{k} - s_{k})
  + \sum_{i=k}^{N-1} \lambda_{i+1}^{T} (h_i (s_i ,q_i ) - s_{i+1})
  \end{align*}
  In dieser Lagrangegleichung wird $ y := (\lambda_{k},s_{k},q_{k},\lambda_{k+1},s_{k+1},q_{k+1}, ...,\lambda_{N},s_{N}) $ verwendet.
  Mit KKT-Bedingung
  \begin{align*}
  \nabla_{y} L^{k}(y)  = 0
  \end{align*}
  und das exakt Newton-Raphson-Verfahren
  \begin{align*}
  y_{i+1} = y_i + \Delta y_i
  \end{align*}
  bei dem jedes $ \Delta y_i $ die Lösung des linearen approximierten Systems
  \begin{align*} 
  \nabla_{y} L^{k}(y_{i}) + J^{k}(y_{i}) \Delta y_{i} = 0
  \end{align*}
  ist.\\
  \newpage
  
  \begin{large}
  \textbf{Pseudo Algorithmus}
  \end{large} \\
  Suche Lösung für das Problem
  \begin{align*}
  \min \sum_{i = k}^{N-1}\frac{1}{2}\Vert l_i (s_i , q_i )\Vert_{2}^{2} +\frac{1}{2}\Vert e (s_N )\Vert_{2}^{2}
  \end{align*}\\
  \\
  0. Wähle Startschätzung $ y^{0} := (\lambda_{0},s_{0},q_{0},\lambda_{1},s_{1},q_{1}, ...,\lambda_{N-1},s_{N-1},q_{N-1},\lambda_{N},s_{N})\in R^{N(n_{\lambda}+n_{s}+n_{q})+ (n_{\lambda_N}+n_{s_N})} $\\
  
  Für $k = 0,1,2,...$ \\
  \\
  1. Berechne $\nabla_y L^{k}(y^{k})$ ohne erste Komponente $x_k$ und berechne
  \begin{align*} 
  J^{k}(y^{k}) =
  \begin{pmatrix}
    & -E  &     &     &     &     &     &     &     &     &     \\
-E  & Q_k^{H} & M_k^{H} & A_k^{T} &  &    &     &     &     &     &     \\
    & (M_k^{T})^{H} & R_k^{H} & B_k^{T} &   &    &    &    &    &   &     \\
    & A_k & B_k &     & -E  &     &     &     &     &     &     \\
    &  &  & -E  & Q_{k+1}^{H} & M_{k+1}^{H} & A_{k+1}^{T} &  &  &  &  \\
    &  &  &     & (M_{k+1}^{T})^{H} & R_{k+1}^{H} & B_{k+1}^{T} &  &  &  &  \\
    &  &  &     & A_{k+1} & B_{k+1} &    &    &     &     &     \\
    &  &  &     &    &    &   & \ddots &     &     &     \\
    &  &  &   &  &  & \ddots & Q_{N-1}^{H} & M_{N-1}^{H} & A_{N-1}^{T} &  \\
    &  &  &   &  &  &    & (M_{N-1}^{T})^{H} & R_{N-1}^{H} & B_{N-1}^{T} &  \\
    &  &  &   &  &  &    & A_{N-1}     & B_{N-1} &    & -E \\
    &  &  &     &    &    &     &      &     & -E &  Q_N^{H} 
\end{pmatrix}
  \end{align*}
  \\
  Mit $ A_i := \dfrac{\partial h_i}{\partial s_i} $, 
  $ B_i := \dfrac{\partial h_i}{\partial q_i} $,
  $
  \begin{pmatrix}
  Q_i^{H} & M_i^{H} \\
  (M_i^{H})^{T} & R_i^{H}
  \end{pmatrix} :=
  \left( 
  \dfrac{\partial l_i (s_i,q_i)}{\partial (s_i,q_i)}
  \right) ^{T}
  \left( 
  \dfrac{\partial l_i (s_i,q_i)}{\partial (s_i,q_i)}
  \right)
  , \ \\
  Q_N^{H} :=
  \left( 
  \dfrac{\partial e (s_N)}{\partial s_N}
  \right) ^{T}
  \left( 
  \dfrac{\partial e (s_N)}{\partial s_N}
  \right)
  $\\
  \\
  \\
  2. Löse $ (J^{k}(y^{k}))^{-1} \nabla_{\lambda_k} L^{k}(y^{k}) $ soweit wie möglich ohne $ x_k $ (Riccati Recursion)\\
  \\
  3. $ x_k $ bekannt \\
  \\
  4. Löse $\Delta y^{k} = (J^{k}(y^{k}))^{-1} \nabla_{y_k} L^{k}(y^{k})$ \\ 
  \\
  5. Gib $ u_k := q_k + \Delta q_k $ an das System \\
  \\
  6. STOP, wenn $ k = N-1 $ \\
  \\
  7. Berechne $ y^{k+1} = \prod ^{k+1} (y^{k} + \Delta y^{k}) \in R^{(N-k-1)(n_{\lambda}+n_{s}+n_{q})+ (n_{\lambda_N}+n_{s_N})} $ \\
  \\
  \newpage
  
  \begin{large}
  \textbf{Konkretes Beispiel}
  \end{large} \\
  Löse das Problem zur minimalen Steuerung $l_i $.
  \begin{align*}
  \min_{\begin{array}{c} s_{k},...,s_{N}\\ q_{k},...,q_{N} \end{array}} \sum_{i=k}^{N} \frac{1}{2} \Vert S_{i}(s_i) \Vert_{2}^{2} + \sum_{i=k}^{N-1} \frac{1}{2} \Vert l_i(q_{i})\Vert_{2}^{2} \ \  
  s.t. \ \left\lbrace \begin{array}{c}
  x_{k} - s_{k} = 0 \\
  h_i (s_i ,q_i ) - s_{i+1} = 0 \ \ \forall i = k, ... , N-1 \end{array} \right. 
  \end{align*}
  $ S_i $ ist in diesem Fall eine Penaltyfunktion, die für die Abweichung vom Kurs bestraft. \\
  \\
  0. Wähle Startschätzung $ y^{0} := (\lambda_{0},s_{0},q_{0},\lambda_{1},s_{1},q_{1}, ...,\lambda_{N-1},s_{N-1},q_{N-1},\lambda_{N},s_{N})$\\
  
  Für $k = 0,1,2,...$ \\
  \\
  1. Berechne $\nabla_y L^{k}(y^{k})$ ohne erste Komponente
  \begin{align*}
  \nabla_y L^{k}(y^{k}) = \left( \begin{array}{c}
  \nabla_{\lambda_{k}} L^{k}(y^{k}) \\ \hline
  \nabla_{s_{k}} L^{k}(y^{k}) \\
  \nabla_{q_{k}} L^{k}(y^{k}) \\
  \vdots \\
  \nabla_{\lambda_{N-1}} L^{k}(y^{k}) \\ 
  \nabla_{s_{N-1}} L^{k}(y^{k}) \\
  \nabla_{q_{N-1}} L^{k}(y^{k}) \\
  \nabla_{\lambda_{N}} L^{k}(y^{k}) \\ 
  \nabla_{s_{N}} L^{k}(y^{k})
  \end{array} \right) 
  \end{align*}
  und berechne Komponenten von $J^{k}(y^{k})$ \\
  \begin{align*}
  \begin{array}{l}
  A_i = \dfrac{\partial h_i(s_i,q_i)}{\partial s_i}= (\nabla_{s_i} h_i)^{T}\\ 
  B_i = \dfrac{\partial h_i(s_i,q_i)}{\partial q_i}= (\nabla_{q_i} h_i)^{T} \\
  Q_i = \nabla_{s_i} S_i *(\nabla_{s_i} S_i )^{T} \\
  M_i = 0 \\
  R_i = \nabla_{q_i} l_i(q_i) * (\nabla_{q_i} l_i(q_i))^{T}
  \end{array}
  \end{align*}
  In diesem Beispiel hängt $ l_i $ nicht von $s_i$ ab, daher ist $M_i$ gleich Null. \\
  \\
  2. Löse $ (J^{k}(y^{k})) \Delta y^{k} =- \nabla_{\lambda_k} L^{k}(y^{k}) $ mit Riccati Recursion.\\
  Betrachte
  \begin{align*}
  \begin{pmatrix}
  -E & Q_{N-1} & 0 & A_{N-1}^{T} &  \\
     & 0 & R_{N-1} & B_{N-1}^{T} &  \\
     & A_{N-1} & B_{N-1} &   & -E \\
     &   &   & -E & Q_N
  \end{pmatrix}
  \begin{pmatrix}
  \Delta \lambda_{N-1} \\
  \Delta s_{N-1} \\
  \Delta q_{N-1} \\
  \Delta \lambda_{N} \\
  \Delta s_N
  \end{pmatrix} =-
  \begin{pmatrix}
  \nabla_{s_{N-1}} L^{k}(y^{k}) \\
  \nabla_{q_{N-1}} L^{k}(y^{k}) \\
  \nabla_{\lambda_{N}} L^{k}(y^{k}) \\ 
  \nabla_{s_{N}} L^{k}(y^{k})
  \end{pmatrix}
  \end{align*}
  Zur einfacheren Schreibweise ist ab jetzt $ \nabla_{s_{N}} := -\nabla_{s_{N}} L^{k}(y^{k}) $
  \begin{align*}
  \begin{pmatrix}
   0  & A_{N-1} & B_{N-1} \\
   0  & 0  &  0 
  \end{pmatrix}
  \begin{pmatrix}
  \Delta \lambda_{N-1} \\
  \Delta s_{N-1} \\
  \Delta q_{N-1} 
  \end{pmatrix} 
  +
  \begin{pmatrix}
   0 & -E \\
   -E  &  Q_N 
  \end{pmatrix}
  \begin{pmatrix}
  \Delta \lambda_{N} \\
  \Delta s_{N} 
  \end{pmatrix} 
  = 
  \begin{pmatrix}
  \nabla_{\lambda_{N}} \\ 
  \nabla_{s_{N}} 
  \end{pmatrix}
  \end{align*}
  Für das Verfahren setzen wir $ P_N = Q_N $.
  \begin{align*}
  \begin{pmatrix}
  \Delta \lambda_{N} \\
  \Delta s_{N} 
  \end{pmatrix}
  =
  \begin{pmatrix}
   0 & -E \\
   -E  &  P_N 
  \end{pmatrix}^{-1}
  \left[ 
  \begin{pmatrix}
  \nabla_{\lambda_{N}} \\ 
  \nabla_{s_{N}} 
  \end{pmatrix}
  -
  \begin{pmatrix}
   0  & A_{N-1} & B_{N-1} \\
   0  & 0  &  0 
  \end{pmatrix}
  \begin{pmatrix}
  \Delta \lambda_{N-1} \\
  \Delta s_{N-1} \\
  \Delta q_{N-1} 
  \end{pmatrix} \right] \\
  =
  \begin{pmatrix}
   -P_N & -E \\
   -E  &   
  \end{pmatrix}
  \left[ 
  \begin{pmatrix}
  \nabla_{\lambda_{N}} \\ 
  \nabla_{s_{N}} 
  \end{pmatrix}
  -
  \begin{pmatrix}
   0  & A_{N-1} & B_{N-1} \\
   0  & 0  &  0 
  \end{pmatrix}
  \begin{pmatrix}
  \Delta \lambda_{N-1} \\
  \Delta s_{N-1} \\
  \Delta q_{N-1} 
  \end{pmatrix} \right] 
  \end{align*}
  Dann werden $\Delta \lambda_{N-1}$,$\Delta s_{N-1}$ und $\Delta q_{N-1}$ gelöst.
  \begin{align*}  
  \begin{pmatrix}
  -E & Q_{N-1}+A_{N-1}^{T}P_N A_{N-1} & A_{N-1}^{T}P_N B_{N-1}  \\
   0 & B_{N-1}^{T}P_N A_{N-1} & R_{N-1}+ B_{N-1}^{T}P_N B_{N-1}
  \end{pmatrix}
  \begin{pmatrix}
  \Delta \lambda_{N-1} \\
  \Delta s_{N-1} \\
  \Delta q_{N-1} 
  \end{pmatrix}
  =
  \begin{pmatrix}
  \nabla_{s_{N-1}} \\ 
  \nabla_{q_{N-1}} 
  \end{pmatrix}
  +
  \begin{pmatrix}
  A_{N-1}^{T}P_N & A_{N-1}^{T} \\
  B_{N-1}^{T}P_N & B_{N-1}^{T}
  \end{pmatrix}
  \begin{pmatrix}
  \nabla_{\lambda_{N}} \\ 
  \nabla_{s_{N}} 
  \end{pmatrix}
  \end{align*}
  Zuerst wird $ \Delta q_{N-1}$ gelöst
  \begin{align*}
  \Delta q_{N-1} =
  (R_{N-1}+B_{N-1}^{T}P_N B_{N-1})^{-1}
  (\nabla_{q_{N-1}}+ B_{N-1}^{T}P_N \nabla_{\lambda_{N}} +
  B_{N-1}^{T}\nabla_{s_{N}} -B_{N-1}^{T}P_N A_{N-1} \Delta s_{N-1})  
  \end{align*}
  Für $\Delta \lambda_{N-1}$ und $\Delta s_{N-1}$ ergibt sich dann
  \begin{align*}
  -\Delta \lambda_{N-1} + P_{N-1}\Delta s_{N-1} = \nabla_{s_{N-1}}^{*}
  \end{align*}
  mit
  \begin{align*}
  \begin{array}{rl}
  P_{N-1} = & Q_{N-1}+A_{N-1}^{T}P_N A_{N-1} -A_{N-1}^{T}P_N B_{N-1}
  (R_{N-1}+B_{N-1}^{T}P_N B_{N-1})^{-1} B_{N-1}^{T}P_N A_{N-1} \\
  \nabla_{s_{N-1}}^{*} = & \nabla_{s_{N-1}} + A_{N-1}^{T}P_N \nabla_{\lambda_{N}} + A_{N-1}^{T}\nabla_{s_{N}} \\
   & - A_{N-1}^{T}P_N B_{N-1}(R_{N-1}+B_{N-1}^{T}P_N B_{N-1})^{-1}(\nabla_{q_{N-1}} +B_{N-1}^{T}P_N \nabla_{\lambda_{N}} +B_{N-1}^{T}\nabla_{s_{N}})
  \end{array}
  \end{align*}
  Damit ergibt sich für das anfängliche System $ J^{k}(y^{k})\Delta y^{k} = -\nabla_{y^{k}} L^{k}(y^{k})$
  \begin{align*}
  \begin{pmatrix}
    & -E &   &   &   &   &   &      \\
  -E& Q_k & 0  &  A_k^{T} &  &   &    &       \\
    & 0   & R_k & B_k^{T} &  &   &   &      \\
    & A_k & B_k &     & \ddots &   &   &    \\
    &  &  & \ddots & Q_{N-2} & 0 & A_{N-2}^{T}  &     \\
    &  &  &        &  0      & R_{N-2}  & B_{N-2}^{T}  &     \\
    &  &  &        & A_{N-2} & B_{N-2}  &     & -E \\
    &  &  &  &  &  & -E & P_{N-1}
  \end{pmatrix}
  \begin{pmatrix}
  \Delta \lambda_{k} \\
  \Delta s_{k} \\
  \Delta q_{k} \\
  \vdots \\
  \Delta \lambda_{N-1} \\
  \Delta s_{N-1} 
  \end{pmatrix} =
  \begin{pmatrix}
  \nabla_{\lambda_{k}} \\
  \nabla_{s_{k}} \\ 
  \nabla_{q_{k}} \\
  \vdots \\
  \nabla_{\lambda_{N-1}} \\
  \nabla_{s_{N-1}}^{*}
  \end{pmatrix}
  \end{align*}
  Die weiteren $P_i $ ergeben sich für $ i = k+1, ..., N-1$
  \begin{align*}
  \begin{array}{rl}
  P_{i-1} = & Q_{i-1}+A_{i-1}^{T}P_i A_{i-1} -A_{i-1}^{T}P_i B_{i-1}
  (R_{i-1}+B_{i-1}^{T}P_i B_{i-1})^{-1} B_{i-1}^{T}P_i A_{i-1} \\
  \nabla_{s_{i-1}}^{*} = & \nabla_{s_{i-1}} + A_{i-1}^{T}P_i \nabla_{\lambda_{i}} + A_{i-1}^{T}\nabla_{s_{i}}^{*} \\
   & - A_{i-1}^{T}P_i B_{i-1}(R_{i-1}+B_{i-1}^{T}P_i B_{i-1})^{-1}(\nabla_{q_{i-1}} +B_{i-1}^{T}P_i \nabla_{\lambda_{i}} +B_{i-1}^{T}\nabla_{s_{i}}^{*})
  \end{array}
  \end{align*}
  Schließlich ergibt sich
  \begin{align*}
  \begin{pmatrix}
  \Delta \lambda_{k} \\
  \Delta s_{k}
  \end{pmatrix} =
  \begin{pmatrix}
  -P_k & -E \\
  -E  & 0 
  \end{pmatrix}
  \begin{pmatrix}
  \nabla_{\lambda_{k}} \\
  \nabla_{s_{k}}^{*}
  \end{pmatrix}
  \end{align*} \\
  3. $x_k$ bekannt. Berechne $\nabla_{\lambda_{k}}=x_k -s_k $
  \begin{align*}
  \Delta q_{k} =
  (R_{k}+B_{k}^{T}P_{k+1} B_{k})^{-1}
  (\nabla_{q_{k}}+ B_{k}^{T}P_{k+1} \nabla_{\lambda_{k+1}} +
  B_{k}^{T}\nabla_{s_{k+1}}^{*} -B_{k}^{T}P_{k+1} A_{k} \Delta s_{k})  
  \end{align*}
  Gib dem System den Wert $u_k = q_k + \Delta q_k $.\\
  Berechne mit Forward Recursion die restlichen Werte von $\Delta y^{k}$
  \begin{align*}
  \begin{pmatrix}
  \Delta \lambda_{i+1} \\
  \Delta s_{i+1}
  \end{pmatrix} =
  \begin{pmatrix}
  -P_{i+1} & -E \\
  -E  & 0 
  \end{pmatrix}
  \left[ 
  \begin{pmatrix}
  \nabla_{\lambda_{i+1}} \\
  \nabla_{s_{i+1}}^{*}
  \end{pmatrix} -
  \begin{pmatrix}
  0 & A_i & B_i \\
  0 & 0 & 0 
  \end{pmatrix}
  \begin{pmatrix}
  \Delta \lambda_{i} \\
  \Delta s_{i} \\
  \Delta q_{i}
  \end{pmatrix} \right] 
  \end{align*}
  Berechne $ y^{k+1} = \prod ^{k+1}(y^{k} + \Delta y^{k})$ \\
  \\
  Dieses Verfahren empfiehlt sich nicht wenn $ N $ zu groß ist.\\
  Eine Alternative wäre, für große $N$, ein fixes $n$ zu wählen und das Verfahren darauf anzuwenden ohne kleiner werdenden Horizont.\\
  \\
  \begin{large}
  \textbf{Riccati mit Constraints}
  \end{large} \\
  Betrachte
  \begin{align*}
  \min_{\begin{array}{c} s_{k},...,s_{N}\\ q_{k},...,q_{N} \end{array}} \sum_{i=k}^{N-1} f_{i}(s_{i},q_{i}) \ \  
  s.t. \ \left\lbrace \begin{array}{c}
  x_{k} - s_{k} = 0 \\
  h_i (s_i ,q_i ) - s_{i+1} = 0 \ \ \forall i = k, ... , N-1 \\
  U_i(q_i) \leq 0 \ \ \forall i = k, ... , N-1 \end{array} \right. 
  \end{align*}
  mit dem Minimalen- und Maximalensteuerungssignal $ u_{min} $ und $u_{max}$ gilt für $C_i $
  \begin{align*}
  U_i(q_i) = \left( \begin{array}{c}
  q_i - u_{max} \\
  u_{min} - q_i    
  \end{array} \right)
  \end{align*}
  Da wir von einer Lösung nahe eines KKT-Punktes ausgehen, interessieren wir uns für den aktiven Teil dieser Constraints. Es gilt $ 0 \leq u_{min} < u_{max}$, was die Sache vereinfacht, da nie beide Constraints gleichzeitig aktiv sein können.
  Suche nach der aktiven Menge. Da es 4 Steuersignale gibt und jedes dieser Signale ein Minimum und ein Maximum besitzt, ergeben sich 8 Constraints. Für die Constraints wird die Variable $ \mu $ gewählt.
  Die Constraint gilt als aktiv in der j-ten Komponente, sollte $U_i^j(q_i) \geq 0$ erfüllt sein.
  
  Es ergibt sich die neue Matrix $J_t(y_t)$
  \begin{align*}
  J_t(y_t) = 
  \begin{pmatrix}
    & -E &   &   &  &  &   &   &  &    \\
  -E& Q_t & M_t  &  & A_t^{T} &  &  &   &    &       \\
    & M_t^T & R_t & C_{A_t}^T &   B_t^{T} &  & &  &   &      \\
    &       & C_{A_t} &         &  &   & &  &    \\
    & A_t & B_t &  &   & \ddots &   & &  &    \\
    &  &  &   & \ddots & Q_{N-1} & M_{N-1} &  & A_{N-1}^{T}  &     \\
    &  &  &  &      & M_{N-1}^T  & R_{N-1} & C_{A_{N-1}}^T & B_{N-1}^{T}  &     \\
    &  &  &  &      &            & C_{A_{N-1}}  & &              &    \\
    &  &  &  &      & A_{N-1} & B_{N-1}  & &    & -E \\
    &  &  &  & &  & &  & -E & Q_{N}
  \end{pmatrix}
  \end{align*}
  $ A_i := \dfrac{\partial h_i}{\partial s_i} $, 
  $ B_i := \dfrac{\partial h_i}{\partial q_i} $,
  $
  \begin{pmatrix}
  Q_i^{H} & M_i^{H} \\
  (M_i^{H})^{T} & R_i^{H}
  \end{pmatrix} :=
  \left( 
  \dfrac{\partial l_i (s_i,q_i)}{\partial (s_i,q_i)}
  \right) ^{T}
  \left( 
  \dfrac{\partial l_i (s_i,q_i)}{\partial (s_i,q_i)}
  \right)
  , C_{A_i} := \dfrac{\partial U_{A_i}}{\partial q_i} \ \\
  Q_N^{H} :=
  \left( 
  \dfrac{\partial e (s_N)}{\partial s_N}
  \right) ^{T}
  \left( 
  \dfrac{\partial e (s_N)}{\partial s_N}
  \right)
  $ \\
  $C_{A_i}$ bezieht sich auf die Ableitungen der aktiven Constraints im Punkt $ i $
  \newpage
  Festlegen der aktiven Menge während des Algorithmus: \\
  Prüfe, ob Contstraints aktiv sind $ U_i(q_i)^j \geq 0 $ \\
  Prüfe, ob zugehöriges $ \mu_i^j > 0 $ erfüllt ist. \\
  Sind beide Bedingungen erfüllt so gilt: $ j\in A_i $ \\
  
  \begin{large}
  \textbf{Riccati Algorithmus}
  \end{large} \\
  Setze $P_N = Q_N$ und $ \nabla_{s_N}^{*} = \nabla_{s_N} $ \\
  Für $i = N,..., t+1 $
  \begin{align*}
  \begin{array}{rl}
  P_{i-1} = & Q_{i-1}+A_{i-1}^{T}P_i A_{i-1} \\
   & - \begin{pmatrix}
   M_{i-1} + A_{i-1}^{T}P_i B_{i-1} & 0
\end{pmatrix}    
  \begin{pmatrix}
  R_{i-1}+B_{i-1}^{T}P_i B_{i-1} & C_{A_i}^T \\
  C_{A_i} & 0
  \end{pmatrix} ^{-1}
  \begin{pmatrix}
  M_{i-1}^T + B_{i-1}^{T}P_i A_{i-1} \\
  0
  \end{pmatrix}
    \\
  \nabla_{s_{i-1}}^{*} = & \nabla_{s_{i-1}} + A_{i-1}^{T}P_i \nabla_{\lambda_{i}} + A_{i-1}^{T}\nabla_{s_{i}}^{*} \\
   & - \begin{pmatrix}
   M_{i-1} + A_{i-1}^{T}P_i B_{i-1} & 0
\end{pmatrix}  
\begin{pmatrix}
R_{i-1}+B_{i-1}^{T}P_i B_{i-1} & C_{A_i}^T \\
C_{A_i} & 0
\end{pmatrix} ^{-1}
\begin{pmatrix}
\nabla_{q_{i-1}} +B_{i-1}^{T}P_i \nabla_{\lambda_{i}} +B_{i-1}^{T}\nabla_{s_{i}}^{*} \\
\nabla_{\mu_{i-1}}
\end{pmatrix}
  \end{array}
  \end{align*}
  Damit lässt sich dann das Problem zusammenfassen auf
  \begin{align*}
  \begin{pmatrix}
  \Delta \lambda_{t} \\
  \Delta s_{t}
  \end{pmatrix} =
  \begin{pmatrix}
  -P_t & -E \\
  -E  & 0 
  \end{pmatrix}
  \begin{pmatrix}
  \nabla_{\lambda_{t}} \\
  \nabla_{s_{t}}^{*}
  \end{pmatrix}
  \end{align*}
  Für die Vorwärtsrekurrsion ergibt sich dann für $ i = t+1,...,N$:
  \begin{align*}
  \begin{pmatrix}
  \Delta q_i \\
  \Delta \mu_i
  \end{pmatrix} =
  \begin{pmatrix}
R_{i-1}+B_{i-1}^{T}P_i B_{i-1} & C_{A_i}^T \\
C_{A_i} & 0
\end{pmatrix} ^{-1}
  \left[ 
  \begin{pmatrix}
\nabla_{q_{i-1}} +B_{i-1}^{T}P_i \nabla_{\lambda_{i}} +B_{i-1}^{T}\nabla_{s_{i}}^{*} \\
\nabla_{\mu_{i-1}}
\end{pmatrix}
  -
  \begin{pmatrix}
  M_{i-1}^T + B_{i-1}^{T}P_i A_{i-1} \\
  0
  \end{pmatrix} \Delta s_{i-1} \right] 
  \end{align*}
  sowie
  \begin{align*}
  \begin{pmatrix}
  \Delta \lambda_{i} \\
  \Delta s_{i}
  \end{pmatrix} =
  \begin{pmatrix}
  -P_i & -E \\
  -E  & 0 
  \end{pmatrix}
  \begin{pmatrix}
  \nabla_{\lambda_{i}} \\
  \nabla_{s_{i}}^{*}
  \end{pmatrix} -
  \begin{pmatrix}
  0 & A_{i-1]
  \end{pmatrix}
  \end{align*}

\end{document}